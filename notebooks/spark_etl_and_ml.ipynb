{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa3fe48-cbe5-461c-a565-ca70f6159113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk@17'\n",
    "os.environ['SPARK_DRIVER_MEMORY'] = '4g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9ec7f0-6323-42e0-a856-e2c7adc27f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc, asc, col\n",
    "from pyspark.sql.functions import from_json, col, regexp_replace, explode, expr\n",
    "from pyspark.sql.types import ArrayType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c05d79d-e936-4698-b15a-343c5707555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/08 06:03:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"PatternAlarm-ETL\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68deffc7-15e3-4d9f-9436-b2d22f8992da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553a4d78-4f8f-42fd-b5cc-b57c0a6290be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_transactions = spark.read.json(\"../data/raw/transactions_samples.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5507fa9-b608-483e-b211-e8300c297b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frauds_labels = spark.read.csv(\n",
    "    \"../data/raw/frauds_labels_samples.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    escape='\"',\n",
    "    quote='\"', \n",
    "    multiLine=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5478094-b140-4663-95b5-bb3d41e9e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/08 06:03:16 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(account_from=None, account_to=None, amount=149.84, billing_address=None, cart_items='[]', country_from=None, country_to=None, currency='EUR', customer_id='A100017', device_fingerprint=None, device_id='ZNHOU4FG7Z8A', domain='gaming', game_id='LOL2Electric', ip_address='45.142.124.124', is_fraud=True, item_name='Premium_weapon_720', item_type='weapon', pattern='fraud_account_takeover', payment_method='steam_wallet', player_id='A100017', purpose=None, session_duration_sec=None, session_length_sec=95, shipping_address=None, timestamp='2025-08-10T22:11:51.290468', timestamp_iso='2025-08-10T22:11:51.290468', transaction_id='txn_017491', transfer_type=None, user_id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bf3acc-fc54-4293-aa04-967a7f2cbb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(alert_id=1, transaction_id='txn_017491', domain='gaming', actor_id='A100017', amount=149.84, transaction_count=1, timestamp=datetime.datetime(2025, 8, 10, 22, 11, 51, 290468), ip_address='45.142.124.124', pattern='fraud_account_takeover', fraud_label=True, fraud_type='fraud_account_takeover', confidence=0.91, label_source='rule_based', label_timestamp=datetime.datetime(2025, 8, 10, 22, 11, 51, 290468), related_transaction_ids='[\"txn_017491\"]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frauds_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3c9e60-c05c-40a7-92f7-b58c5fa1e2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|related_transaction_ids|\n",
      "+-----------------------+\n",
      "|[\"txn_017491\"]         |\n",
      "|[\"txn_017764\"]         |\n",
      "|[\"txn_017714\"]         |\n",
      "+-----------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "df_frauds_labels.select(\"related_transaction_ids\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da48c347-039d-42d0-ba40-04b46065999a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_frauds_parsed = df_frauds_labels.withColumn(\n",
    "    \"related_ids_parsed\",\n",
    "    from_json(col(\"related_transaction_ids\"), ArrayType(StringType()))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee88a5cf-f0ca-4f99-82df-e43c3603113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------+\n",
      "|related_transaction_ids|related_ids_parsed|\n",
      "+-----------------------+------------------+\n",
      "|[\"txn_017491\"]         |[txn_017491]      |\n",
      "|[\"txn_017764\"]         |[txn_017764]      |\n",
      "|[\"txn_017714\"]         |[txn_017714]      |\n",
      "+-----------------------+------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "df_frauds_parsed.select(\"related_transaction_ids\", \"related_ids_parsed\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6486adfe-1663-4f4c-b708-58ac90e6158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frauds_exploded = df_frauds_parsed.withColumn(\n",
    "    \"related_txn_id\",\n",
    "    explode(col(\"related_ids_parsed\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9ea34de-8d77-4e74-b5a5-65ce5703e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|alert_id|related_txn_id|\n",
      "+--------+--------------+\n",
      "|1       |txn_017491    |\n",
      "|2       |txn_017764    |\n",
      "|3       |txn_017714    |\n",
      "|4       |txn_017702    |\n",
      "|5       |txn_118300    |\n",
      "+--------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_frauds_exploded.select(\"alert_id\", \"related_txn_id\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec40dfda-b5ec-4e02-bdfb-23f4a97005eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frauds_renamed = df_frauds_exploded.select(\n",
    "    col(\"alert_id\"),\n",
    "    col(\"transaction_id\").alias(\"fraud_alert_txn_id\"),  # Colonne pivot du fraud\n",
    "    col(\"domain\").alias(\"fraud_domain\"),\n",
    "    col(\"actor_id\").alias(\"fraud_actor_id\"),\n",
    "    col(\"amount\").alias(\"fraud_total_amount\"),  # ‚úÖ Montant agr√©g√©\n",
    "    col(\"transaction_count\").alias(\"fraud_txn_count\"),\n",
    "    col(\"timestamp\").alias(\"fraud_first_seen\"),\n",
    "    col(\"ip_address\").alias(\"fraud_ip\"),\n",
    "    col(\"pattern\").alias(\"fraud_pattern\"),\n",
    "    col(\"fraud_label\"),\n",
    "    col(\"fraud_type\"),\n",
    "    col(\"confidence\"),\n",
    "    col(\"label_source\"),\n",
    "    col(\"label_timestamp\"),\n",
    "    col(\"related_txn_id\")  # ‚úÖ Cl√© de join\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8344aa44-b78f-44cd-8a1a-5bc3f32c7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_frauds_renamed.join(\n",
    "    df_transactions,\n",
    "    df_frauds_exploded.related_txn_id == df_transactions.transaction_id,\n",
    "    \"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b8abc6-b314-41e7-8787-ce04436db4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frauds: 194826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frauds exploded: 200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions: 200000\n",
      "Join result: 200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(f\"Frauds: {df_frauds_labels.count()}\")\n",
    "print(f\"Frauds exploded: {df_frauds_exploded.count()}\")\n",
    "print(f\"Transactions: {df_transactions.count()}\")\n",
    "print(f\"Join result: {df_join.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe7afd92-7b7f-428a-8533-7fcc18552967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_join.write.mode(\"overwrite\").partitionBy(\"domain\").parquet(\"../data/processed/training_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff242f28-0198-44c8-b7a8-d4637352d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Part - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5620059c-6981-4a45-a907-e0353cd7fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = spark.read.parquet(\"../data/processed/training_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e558e21-ed08-4490-adb0-918e6cc87175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   domain|count|\n",
      "+---------+-----+\n",
      "|ecommerce|65000|\n",
      "|   gaming|70000|\n",
      "|  fintech|65000|\n",
      "+---------+-----+\n",
      "\n",
      "+--------------------+-----+\n",
      "|       fraud_pattern|count|\n",
      "+--------------------+-----+\n",
      "|fraud_friendly_fraud| 1725|\n",
      "|regular_window_sh...|11849|\n",
      "|  fraud_card_testing| 4054|\n",
      "|     regular_shopper|44927|\n",
      "|   fraud_promo_abuse| 2445|\n",
      "|  fraud_gold_farming| 3596|\n",
      "|fraud_chargeback_...| 1220|\n",
      "|fraud_account_tak...| 4034|\n",
      "|     regular_grinder|13109|\n",
      "|regular_casual_pl...|32588|\n",
      "|regular_whale_spe...|15453|\n",
      "|       regular_saver|29914|\n",
      "|fraud_synthetic_i...| 1450|\n",
      "|  regular_bill_payer|28954|\n",
      "|   fraud_structuring| 1949|\n",
      "|fraud_money_laund...| 2733|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_training.groupBy(\"domain\").count().show()\n",
    "df_training.groupBy(\"fraud_pattern\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5e6a24c-94e1-4382-858c-f374ad2c1d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a59beaa-0ca6-4f5c-a2e0-f77e526e12ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alert_id: integer (nullable = true)\n",
      " |-- fraud_alert_txn_id: string (nullable = true)\n",
      " |-- fraud_domain: string (nullable = true)\n",
      " |-- fraud_actor_id: string (nullable = true)\n",
      " |-- fraud_total_amount: double (nullable = true)\n",
      " |-- fraud_txn_count: integer (nullable = true)\n",
      " |-- fraud_first_seen: timestamp (nullable = true)\n",
      " |-- fraud_ip: string (nullable = true)\n",
      " |-- fraud_pattern: string (nullable = true)\n",
      " |-- fraud_label: boolean (nullable = true)\n",
      " |-- fraud_type: string (nullable = true)\n",
      " |-- confidence: double (nullable = true)\n",
      " |-- label_source: string (nullable = true)\n",
      " |-- label_timestamp: timestamp (nullable = true)\n",
      " |-- related_txn_id: string (nullable = true)\n",
      " |-- account_from: string (nullable = true)\n",
      " |-- account_to: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- billing_address: struct (nullable = true)\n",
      " |    |-- city: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- street: string (nullable = true)\n",
      " |    |-- zip: string (nullable = true)\n",
      " |-- cart_items: string (nullable = true)\n",
      " |-- country_from: string (nullable = true)\n",
      " |-- country_to: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- device_fingerprint: string (nullable = true)\n",
      " |-- device_id: string (nullable = true)\n",
      " |-- game_id: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- is_fraud: boolean (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_type: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- player_id: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- session_duration_sec: long (nullable = true)\n",
      " |-- session_length_sec: long (nullable = true)\n",
      " |-- shipping_address: struct (nullable = true)\n",
      " |    |-- city: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- street: string (nullable = true)\n",
      " |    |-- zip: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- timestamp_iso: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- transfer_type: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16070c61-a550-418f-bf8c-991c6c9bbdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    to_timestamp, col, when, coalesce, \n",
    "    hour, dayofweek, regexp_replace\n",
    ")\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e447f48d-3f8c-462e-8f77-11f5c26f1c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 200,000 training samples\n",
      "+---------+-----+\n",
      "|   domain|count|\n",
      "+---------+-----+\n",
      "|ecommerce|65000|\n",
      "|   gaming|70000|\n",
      "|  fintech|65000|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 - Load Data\n",
    "\n",
    "df_training = spark.read.parquet(\"../data/processed/training_data.parquet\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {df_training.count():,} training samples\")\n",
    "df_training.groupBy(\"domain\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "438ba41b-f9b2-4e5a-b5c5-4f1ec743435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature engineering complete (15 features)\n",
      "‚úÖ Classes: 10 (1 regular + 7 fraud types)\n"
     ]
    }
   ],
   "source": [
    "#3 : Feature Engineering\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Constants\n",
    "HIGH_RISK_COUNTRIES = ['KY', 'PA', 'BZ', 'VG']\n",
    "\n",
    "# Fix timestamp type\n",
    "df_fixed = df_training.withColumn(\n",
    "    \"timestamp\",\n",
    "    to_timestamp(col(\"timestamp\"))\n",
    ")\n",
    "\n",
    "# Create all features\n",
    "df_features = df_fixed \\\n",
    "    .withColumn(\"country_mismatch\",\n",
    "        when(\n",
    "            col(\"country_from\").isNotNull() & col(\"country_to\").isNotNull(),\n",
    "            (col(\"country_from\") != col(\"country_to\")).cast(\"int\")\n",
    "        ).otherwise(0)\n",
    "    ) \\\n",
    "    .withColumn(\"hour_of_day\", \n",
    "        hour(col(\"fraud_first_seen\"))\n",
    "    ) \\\n",
    "    .withColumn(\"day_of_week\", \n",
    "        dayofweek(col(\"fraud_first_seen\"))\n",
    "    ) \\\n",
    "    .withColumn(\"is_weekend\", \n",
    "        (dayofweek(col(\"fraud_first_seen\")).isin([1, 7])).cast(\"int\")\n",
    "    ) \\\n",
    "    .withColumn(\"is_near_threshold\", \n",
    "        ((col(\"amount\") >= 9500) & (col(\"amount\") < 10000)).cast(\"int\")\n",
    "    ) \\\n",
    "    .withColumn(\"involves_high_risk_country\",\n",
    "        when(\n",
    "            col(\"country_to\").isNotNull() | col(\"country_from\").isNotNull(),\n",
    "            (col(\"country_to\").isin(HIGH_RISK_COUNTRIES) | \n",
    "             col(\"country_from\").isin(HIGH_RISK_COUNTRIES)).cast(\"int\")\n",
    "        ).otherwise(0)\n",
    "    ) \\\n",
    "    .withColumn(\"is_rapid_session\",\n",
    "        when(\n",
    "            col(\"session_length_sec\").isNotNull(),\n",
    "            (col(\"session_length_sec\") < 120).cast(\"int\")\n",
    "        ).otherwise(0)\n",
    "    ) \\\n",
    "    .withColumn(\"amount_per_txn\",\n",
    "        col(\"amount\") / (col(\"fraud_txn_count\") + 1)\n",
    "    ) \\\n",
    "    .withColumn(\"session_efficiency\",\n",
    "        col(\"amount\") / (col(\"session_length_sec\") + 1)\n",
    "    ) \\\n",
    "    .withColumn(\"night_rapid_combo\",\n",
    "        (((col(\"hour_of_day\") < 6) | (col(\"hour_of_day\") > 22)) & \n",
    "         (col(\"is_rapid_session\") == 1)).cast(\"int\")\n",
    "    ) \\\n",
    "    .withColumn(\"fraud_pattern_simplified\",  # ‚úÖ NEW - Merge all regulars!\n",
    "        when(col(\"fraud_pattern\").startswith(\"regular_\"), lit(\"regular\"))\n",
    "        .otherwise(col(\"fraud_pattern\"))\n",
    "    )\n",
    "\n",
    "# Fill ALL NULL values\n",
    "df_clean = df_features.na.fill({\n",
    "    \"session_length_sec\": 0,\n",
    "    \"payment_method\": \"unknown\",\n",
    "    \"hour_of_day\": 12,\n",
    "    \"day_of_week\": 3,\n",
    "    \"is_weekend\": 0,\n",
    "    \"is_near_threshold\": 0,\n",
    "    \"involves_high_risk_country\": 0,\n",
    "    \"is_rapid_session\": 0,\n",
    "    \"amount_per_txn\": 0,\n",
    "    \"session_efficiency\": 0,\n",
    "    \"night_rapid_combo\": 0\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Feature engineering complete (15 features)\")\n",
    "print(f\"‚úÖ Classes: {df_clean.select('fraud_pattern_simplified').distinct().count()} (1 regular + 7 fraud types)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ebf307c-f96a-4157-831c-4b7a4117f4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Computing class weights...\n",
      "Class weights:\n",
      "  fraud_chargeback_fraud: 10.25\n",
      "  fraud_synthetic_identity: 8.62\n",
      "  fraud_friendly_fraud: 7.25\n",
      "  fraud_structuring: 6.41\n",
      "  fraud_promo_abuse: 5.11\n",
      "‚úÖ Class weights applied\n"
     ]
    }
   ],
   "source": [
    "#4: Compute class weights\n",
    "\n",
    "# Compute class weights\n",
    "print(\"\\nüìä Computing class weights...\")\n",
    "\n",
    "class_counts = df_clean.groupBy(\"fraud_pattern\").count().collect()\n",
    "total = sum([row['count'] for row in class_counts])\n",
    "\n",
    "# Create weight map\n",
    "weight_map = {row['fraud_pattern']: total / (16 * row['count']) \n",
    "              for row in class_counts}\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for pattern, weight in sorted(weight_map.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"  {pattern}: {weight:.2f}\")\n",
    "\n",
    "# Add weight column\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def get_weight(pattern):\n",
    "    return weight_map.get(pattern, 1.0)\n",
    "\n",
    "df_weighted = df_clean.withColumn(\"class_weight\", get_weight(col(\"fraud_pattern\")))\n",
    "\n",
    "print(\"‚úÖ Class weights applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21c878c5-9cbc-4ff9-80b4-c0d2e5e651f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline configured (15 features, 8 classes)\n"
     ]
    }
   ],
   "source": [
    "#5 : Pipeline Setup\n",
    "\n",
    "# Feature columns (15 features)\n",
    "feature_cols = [\n",
    "    \"amount\",\n",
    "    \"fraud_txn_count\", \n",
    "    \"session_length_sec\",\n",
    "    \"country_mismatch\",\n",
    "    \"hour_of_day\",\n",
    "    \"day_of_week\",\n",
    "    \"is_weekend\",\n",
    "    \"is_near_threshold\",\n",
    "    \"involves_high_risk_country\",\n",
    "    \"is_rapid_session\",\n",
    "    \"amount_per_txn\",       \n",
    "    \"session_efficiency\",    \n",
    "    \"night_rapid_combo\",  \n",
    "    \"payment_idx\",\n",
    "    \"domain_idx\"\n",
    "]\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=\"payment_method\", outputCol=\"payment_idx\"),\n",
    "    StringIndexer(inputCol=\"domain\", outputCol=\"domain_idx\"),\n",
    "    StringIndexer(inputCol=\"fraud_pattern_simplified\", outputCol=\"label_idx\"),  # ‚úÖ Use simplified!\n",
    "    VectorAssembler(inputCols=feature_cols, outputCol=\"features\"),\n",
    "    RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label_idx\",\n",
    "        numTrees=150,\n",
    "        maxDepth=16,\n",
    "        minInstancesPerNode=3,\n",
    "        maxBins=64,\n",
    "        # ‚ùå NO weightCol\n",
    "        seed=42\n",
    "    )\n",
    "])\n",
    "\n",
    "print(f\"‚úÖ Pipeline configured (15 features, 8 classes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de62733-b047-4575-bcb3-2a314d2b592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 160,136 samples\n",
      "Test: 39,864 samples\n",
      "\n",
      "üìä Class Distribution:\n",
      "+------------------------+------+\n",
      "|fraud_pattern_simplified| count|\n",
      "+------------------------+------+\n",
      "|                 regular|141456|\n",
      "|    fraud_account_tak...|  3280|\n",
      "|      fraud_card_testing|  3259|\n",
      "|      fraud_gold_farming|  2909|\n",
      "|    fraud_money_laund...|  2182|\n",
      "|       fraud_promo_abuse|  1953|\n",
      "|       fraud_structuring|  1586|\n",
      "|    fraud_friendly_fraud|  1377|\n",
      "|    fraud_synthetic_i...|  1186|\n",
      "|    fraud_chargeback_...|   948|\n",
      "+------------------------+------+\n",
      "\n",
      "\n",
      "üöÄ Training RandomForest (8 classes: 1 regular + 7 fraud types)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/08 06:04:10 WARN DAGScheduler: Broadcasting large task binary with size 1496.2 KiB\n",
      "25/11/08 06:04:11 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/11/08 06:04:12 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "25/11/08 06:04:14 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "25/11/08 06:04:16 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "25/11/08 06:04:17 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "25/11/08 06:04:19 WARN DAGScheduler: Broadcasting large task binary with size 1009.7 KiB\n",
      "25/11/08 06:04:19 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n",
      "25/11/08 06:04:21 WARN DAGScheduler: Broadcasting large task binary with size 1287.8 KiB\n",
      "25/11/08 06:04:22 WARN DAGScheduler: Broadcasting large task binary with size 12.8 MiB\n",
      "25/11/08 06:04:24 WARN DAGScheduler: Broadcasting large task binary with size 1597.5 KiB\n",
      "25/11/08 06:04:24 WARN DAGScheduler: Broadcasting large task binary with size 16.3 MiB\n",
      "25/11/08 06:04:26 WARN DAGScheduler: Broadcasting large task binary with size 1854.1 KiB\n",
      "25/11/08 06:04:27 WARN DAGScheduler: Broadcasting large task binary with size 20.1 MiB\n",
      "25/11/08 06:04:30 WARN DAGScheduler: Broadcasting large task binary with size 1998.8 KiB\n",
      "25/11/08 06:04:31 WARN DAGScheduler: Broadcasting large task binary with size 24.1 MiB\n",
      "25/11/08 06:04:33 WARN DAGScheduler: Broadcasting large task binary with size 2010.0 KiB\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete!\n"
     ]
    }
   ],
   "source": [
    "#5 : Train/Test Split & Training\n",
    "\n",
    "# Split data (use df_weighted now)\n",
    "train, test = df_clean.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Train: {train.count():,} samples\")\n",
    "print(f\"Test: {test.count():,} samples\")\n",
    "\n",
    "# Show class distribution\n",
    "print(\"\\nüìä Class Distribution:\")\n",
    "train.groupBy(\"fraud_pattern_simplified\").count().orderBy(col(\"count\").desc()).show()\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüöÄ Training RandomForest (8 classes: 1 regular + 7 fraud types)...\")\n",
    "model = pipeline.fit(train)\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e084c08-623a-43fb-8bca-1744b9e0df75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Sample Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/08 06:04:56 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|fraud_pattern         |label_idx|prediction|probability                                                                                                                                                                       |\n",
      "+----------------------+---------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|regular_shopper       |0.0      |0.0       |[0.9583338711940685,0.0,0.008638383340530307,0.0,0.0,0.02526986364419497,0.0,0.007738464373728143,1.9417447477910585E-5,0.0]                                                      |\n",
      "|regular_shopper       |0.0      |0.0       |[0.9701939594729959,0.0,0.0029080417493700596,0.0,0.0,0.016819710224405912,0.0,0.010042869076669516,3.5419476558759124E-5,0.0]                                                    |\n",
      "|regular_shopper       |0.0      |0.0       |[0.9707029920365519,0.0,0.0025023283383752547,0.0,0.0,0.01543270206880352,0.0,0.01133083521422599,3.1142342043137806E-5,0.0]                                                      |\n",
      "|regular_shopper       |0.0      |0.0       |[0.9461293066761791,2.292291074115564E-4,0.022135823784796393,3.1068961656980157E-4,0.0,0.018833060636863793,0.0,0.011994525956419349,1.8892996577549855E-5,3.4847122518228535E-4]|\n",
      "|regular_shopper       |0.0      |0.0       |[0.9707922872533373,0.0,0.0031666998560294646,0.0,0.0,0.015387130005695708,0.0,0.010620079989042125,3.38028958953642E-5,0.0]                                                      |\n",
      "|regular_shopper       |0.0      |0.0       |[0.9706292600606531,0.0,0.0028376273205670487,0.0,0.0,0.01765536838970158,0.0,0.00885188311227933,2.5861116798881136E-5,0.0]                                                      |\n",
      "|regular_window_shopper|0.0      |0.0       |[0.9703498564992873,0.0,0.002917218165979373,0.0,0.0,0.016383884182981045,0.0,0.01031362167519363,3.541947655875912E-5,0.0]                                                       |\n",
      "|regular_shopper       |0.0      |0.0       |[0.9695458458393084,0.0,0.0032229479230050217,0.0,0.0,0.014879936757068111,0.0,0.012320159804396838,3.110967622140577E-5,0.0]                                                     |\n",
      "|regular_window_shopper|0.0      |0.0       |[0.9705579476983723,0.0,0.002516519703475412,0.0,0.0,0.016644836437311284,0.0,0.010249553818797849,3.11423420431378E-5,0.0]                                                       |\n",
      "|regular_shopper       |0.0      |0.0       |[0.9640372918556076,0.0,0.0021389259040674007,0.0,0.001908496732026143,0.008449976464524977,0.0010384215991692623,0.006097605407895597,0.016329282036709036,0.0]                  |\n",
      "+----------------------+---------+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/08 06:04:57 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "25/11/08 06:04:58 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "[Stage 120:==================================================>      (8 + 1) / 9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Accuracy: 97.50%\n",
      "üéØ F1 Score: 97.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#6 : Predictions & Evaluation\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\nüìä Sample Predictions:\")\n",
    "predictions.select(\n",
    "    \"fraud_pattern\", \n",
    "    \"label_idx\", \n",
    "    \"prediction\", \n",
    "    \"probability\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "# Accuracy\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_idx\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "\n",
    "# F1 Score\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_idx\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"\\nüéØ Accuracy: {accuracy:.2%}\")\n",
    "print(f\"üéØ F1 Score: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a07221f-10e9-4daa-878e-bae1df15922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Confusion Matrix Analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acourreg/Documents/Workspace/portfolio/patternalarm/venv/lib/python3.11/site-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "25/11/08 06:05:04 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "25/11/08 06:05:05 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:======>                                                  (1 + 8) / 9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         0    1    2    3    4    5    6    7    8    9\n",
      "  0 | 35091    0  232    0    0    7    0    8    0    0  | regular\n",
      "  1 |     0  752    0    0    0    0    0    0    0    2  | fraud_account_takeover\n",
      "  2 |   179    0  615    0    0    1    0    0    0    0  | fraud_card_testing\n",
      "  3 |     0    0    0  687    0    0    0    0    0    0  | fraud_gold_farming\n",
      "  4 |     0    0    0    0  533    0    0    0   18    0  | fraud_money_laundering\n",
      "  5 |   250    0   26    0    0  146    0   70    0    0  | fraud_promo_abuse\n",
      "  6 |     0    0    0    0    0    0  363    0    0    0  | fraud_structuring\n",
      "  7 |   125    0    1    0    0   48    0  174    0    0  | fraud_friendly_fraud\n",
      "  8 |     0    0    0    0    8    0    4    0  252    0  | fraud_synthetic_identity\n",
      "  9 |     0   17    0    0    0    0    0    0    0  255  | fraud_chargeback_fraud\n",
      "\n",
      "üìà Per-Class Performance:\n",
      "Class                          |  Precision |     Recall |         F1\n",
      "----------------------------------------------------------------------\n",
      "regular                        |     98.45% |     99.30% |     98.87%\n",
      "fraud_account_takeover         |     97.79% |     99.73% |     98.75%\n",
      "fraud_card_testing             |     70.37% |     77.36% |     73.70%\n",
      "fraud_gold_farming             |    100.00% |    100.00% |    100.00%\n",
      "fraud_money_laundering         |     98.52% |     96.73% |     97.62%\n",
      "fraud_promo_abuse              |     72.28% |     29.67% |     42.07%\n",
      "fraud_structuring              |     98.91% |    100.00% |     99.45%\n",
      "fraud_friendly_fraud           |     69.05% |     50.00% |     58.00%\n",
      "fraud_synthetic_identity       |     93.33% |     95.45% |     94.38%\n",
      "fraud_chargeback_fraud         |     99.22% |     93.75% |     96.41%\n",
      "\n",
      "‚ùå Worst Performing Classes (F1 < 70%):\n",
      "  fraud_promo_abuse             : 42.07%\n",
      "  fraud_friendly_fraud          : 58.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#7 Confusion Matrix & Error Analysis\n",
    "\n",
    "# 7Ô∏è‚É£ Confusion Matrix & Error Analysis\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics  # ‚úÖ mllib, pas ml\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ Confusion Matrix\n",
    "print(\"\\nüìä Confusion Matrix Analysis:\")\n",
    "\n",
    "# Prepare data for MulticlassMetrics\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"label_idx\").rdd.map(\n",
    "    lambda row: (float(row.prediction), float(row.label_idx))\n",
    ")\n",
    "\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Get label names\n",
    "label_indexer = model.stages[2]  # StringIndexer for fraud_pattern\n",
    "labels = label_indexer.labels\n",
    "\n",
    "print(\"\\nüîç Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Print with labels (abbreviated)\n",
    "print(f\"\\n{'':5s}\", end=\"\")\n",
    "for i in range(len(labels)):\n",
    "    print(f\"{i:5d}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print(f\"{i:3d} | \", end=\"\")\n",
    "    for j in range(len(labels)):\n",
    "        print(f\"{int(confusion_matrix[i][j]):5d}\", end=\"\")\n",
    "    print(f\"  | {labels[i][:30]}\")\n",
    "\n",
    "# 2Ô∏è‚É£ Per-class metrics\n",
    "print(\"\\nüìà Per-Class Performance:\")\n",
    "print(f\"{'Class':30s} | {'Precision':>10s} | {'Recall':>10s} | {'F1':>10s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    precision = metrics.precision(float(i))\n",
    "    recall = metrics.recall(float(i))\n",
    "    f1 = metrics.fMeasure(float(i))\n",
    "    print(f\"{label:30s} | {precision:10.2%} | {recall:10.2%} | {f1:10.2%}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Worst performers\n",
    "print(\"\\n‚ùå Worst Performing Classes (F1 < 70%):\")\n",
    "worst = [(label, metrics.fMeasure(float(i))) \n",
    "         for i, label in enumerate(labels) \n",
    "         if metrics.fMeasure(float(i)) < 0.70]\n",
    "\n",
    "for label, f1 in sorted(worst, key=lambda x: x[1]):\n",
    "    print(f\"  {label:30s}: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "072722a8-02c1-4105-a45c-ef164b380746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Deleted old model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acourreg/Documents/Workspace/portfolio/patternalarm/venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/11/08 06:27:38 INFO mlflow.tracking.fluent: Experiment with name 'fraud_detection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark model saved to ../data/models/fraud_detector_v1\n",
      "‚úÖ MLflow model logged\n",
      "   Run ID: 0a8ee170f87a4350b4d03d21270f99b4\n",
      "   URI: runs:/0a8ee170f87a4350b4d03d21270f99b4/model\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Save Model (Spark + MLflow)\n",
    "# ============================================================================\n",
    "\n",
    "import shutil\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 1Ô∏è‚É£ Save Spark model locally\n",
    "model_path = Path(\"../data/models/fraud_detector_v1\")\n",
    "\n",
    "if model_path.exists():\n",
    "    shutil.rmtree(model_path)\n",
    "    print(f\"üóëÔ∏è  Deleted old model\")\n",
    "\n",
    "model.write().overwrite().save(str(model_path))\n",
    "print(f\"‚úÖ Spark model saved to {model_path}\")\n",
    "\n",
    "# 2Ô∏è‚É£ Log to MLflow (same parent folder)\n",
    "mlflow_path = Path(\"../data/models/mlflow_tracking\")\n",
    "mlflow_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(f\"file:{mlflow_path.absolute()}\")\n",
    "mlflow.set_experiment(\"fraud_detection\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "    mlflow.log_metric(\"accuracy\", 0.975)\n",
    "    mlflow.log_metric(\"f1_score\", 0.973)\n",
    "    mlflow.log_param(\"num_trees\", 150)\n",
    "    mlflow.log_param(\"max_depth\", 16)\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    \n",
    "    # Save URI for FastAPI\n",
    "    (model_path.parent / \"mlflow_model_uri.txt\").write_text(model_uri)\n",
    "    \n",
    "    print(f\"‚úÖ MLflow model logged\")\n",
    "    print(f\"   Run ID: {run_id}\")\n",
    "    print(f\"   URI: {model_uri}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Save README\n",
    "(model_path / \"README.md\").write_text(f\"\"\"# Fraud Detection Model v1\n",
    "- **Accuracy: 97.50%**\n",
    "- **F1 Score: 97.27%**\n",
    "- **Classes: 8** (1 regular + 7 fraud types)\n",
    "- **Training Date:** {datetime.now().strftime('%Y-%m-%d')}\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f9c8a-ab5d-4073-b47a-14856cef2327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
